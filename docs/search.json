[
  {
    "objectID": "manuscript/reproducibility.html",
    "href": "manuscript/reproducibility.html",
    "title": "Reproducibility Supplement",
    "section": "",
    "text": "This document provides computer code that was used to create the tables, figures, and results which we report in our manuscript Multi-week Forecasting of Pediatric Blood and Marrow Transplant Hospital Census: Development and Real-World Validation. We provide this document to allow other interested parties to inspect, verify, and reproduce our analytic work.\nThe first section lists concise descriptions of the steps performed in our Analyses. To view the code (written in the R programming language) that was used to perform a specific step, as well as the results, click the black triangle to the left of the description to expand each section. The code relies heavily on the BMTCensusManuscript package developed to house code to reproduce the manuscript results. While the order of this section mirrors the order of results reported in the main manuscript, the section headings follow an analytical order laid out in the Materials and Methods section of the manuscript to allow greater depth in this document. Tables and figures from the main manuscript and supplementary materials are cross-referenced.\nThe second section describes the precise Computational Environment in which the computational analyses were performed. Among other parameters, this part lists the names, versions, and sources of all software packages that were used to generate this document."
  },
  {
    "objectID": "manuscript/reproducibility.html#setup",
    "href": "manuscript/reproducibility.html#setup",
    "title": "Reproducibility Supplement",
    "section": "Setup",
    "text": "Setup\n\n\nLoad required libraries\n\n\nlibrary(conflicted)\n\nconflicts_prefer(dplyr::filter)\n\nlibrary(BMTCensusManuscript)\nlibrary(tidyverse)\nlibrary(timetk)\nlibrary(rsample)\nlibrary(parsnip)\nlibrary(workflows)\nlibrary(workflowsets)\nlibrary(modeltime)\nlibrary(modeltime.resample)\nlibrary(poissonreg)\nlibrary(parallel)\nlibrary(future)\nlibrary(dials)\nlibrary(recipes)\nlibrary(tune)\nlibrary(yardstick)\nlibrary(kableExtra)\n\ntheme_set(theme_minimal())"
  },
  {
    "objectID": "manuscript/reproducibility.html#data",
    "href": "manuscript/reproducibility.html#data",
    "title": "Reproducibility Supplement",
    "section": "Data",
    "text": "Data\n\n\nLoad census, admissions, and scheduled admissions data\n\n\ntrain_test_split_date &lt;- as_date(\"2022-09-30\")\n\ncensus_data &lt;- readRDS(\"manuscript/data/census.rds\")\nadmission_data &lt;- readRDS(\"manuscript/data/admissions.rds\")\nscheduled_admissions &lt;- readRDS(\"manuscript/data/scheduled_admissions.rds\") |&gt;\n  count(transplant_type, date, admission_date, name = \"scheduled\")\n\n\n\n\nPlot length of stay by admission type (Figure 1a)\n\n\n# Date when the data was refreshed\ncensoring_date &lt;- as_date(\"2024-2-29\")\n\nmanuscript_census_data &lt;- census_data |&gt;\n  mutate(\n    admission_type = case_match(\n      transplant_type,\n      \"Allogeneic\" ~ \"Allo HSCT\",\n      \"Autologous\" ~ \"Auto HSCT\",\n      \"No Transplant\" ~ \"Other\"\n    ),\n    admission_type = factor(admission_type, levels = c(\"Auto HSCT\", \"Allo HSCT\", \"Other\"), ordered = TRUE),\n    admission_type_malig = case_when(\n      admission_type == \"Allo HSCT\" & malignant == \"Yes\" ~ \"Allo HSCT (Malignant)\",\n      admission_type == \"Allo HSCT\" & malignant == \"No\" ~ \"Allo HSCT (Non-Malignant)\",\n      .default = admission_type\n    ),\n    admission_type_malig = factor(admission_type_malig, levels = c(\"Auto HSCT\", \"Allo HSCT (Malignant)\", \"Allo HSCT (Non-Malignant)\", \"Other\"), ordered = TRUE)\n  )\n\nmanuscript_encounter_data &lt;- manuscript_census_data |&gt;\n  filter(bmt_team_start_date &gt;= \"2016-01-01\") |&gt;\n  distinct(csn, bmt_team_start_date, bmt_team_end_date, admission_type, malignant, malignancy_history, admission_type_malig) |&gt;\n  mutate(\n    censored = is.na(bmt_team_end_date),\n    los = as.numeric(coalesce(bmt_team_end_date, censoring_date) - bmt_team_start_date, unit = \"days\")\n  )\n\nmanuscript_encounter_data |&gt;\n  ggplot(aes(x = los, color = admission_type)) +\n  geom_density() +\n  coord_cartesian(xlim = c(0, 80)) +\n  labs(\n    x = \"Length of Stay (Days)\",\n    y = NULL,\n    color = \"Admission Type\"\n  ) +\n  theme(axis.text.y = element_blank()) +\n  scale_color_chop()\n\n\n\n\n\n\n\n\n\n\n\nPlot daily census by admission type (Figure 1b)\n\n\nfig_1b_data &lt;- manuscript_census_data |&gt;\n  filter(time &gt; 0, date &gt;= \"2021-01-01\") |&gt;\n  count(date, admission_type, name = \"value\") |&gt;\n  complete(\n    date = seq(as_date(\"2021-01-01\"), as_date(\"2023-06-30\"), by = \"day\"),\n    admission_type,\n    fill = list(value = 0)\n  )\n\nfig_1b_data |&gt;\n  ggplot(aes(x = date, y = value, fill = admission_type)) +\n  geom_area(aes(group = fct_relevel(admission_type, \"Allo HSCT\", after = Inf))) +\n  labs(\n    fill = \"Admission Type\",\n    y = \"Midnight Census\",\n    x = NULL\n  ) +\n  scale_fill_chop() +\n  scale_x_date(date_labels = \"%b '%y\")\n\n\n\n\n\n\n\n\n\n\n\nSchematic overview of census prediction model (Figure 2a)\n\n\n\n\n\nPlot representative example of census components (Figure 2b)\n\n\nfig_2b &lt;- list()\n\nfig_2b$date &lt;- as_date(\"2023-04-01\")\nfig_2b$h &lt;- 65\n\nfig_2b$base_data &lt;- manuscript_census_data |&gt;\n  filter(time &gt; 0, date == fig_2b$date)\n\nfig_2b$current_admit_data &lt;- fig_2b$base_data |&gt;\n  extend_discharge_data(fig_2b$h, end_var = bmt_team_end_date) |&gt;\n  mutate(date = fig_2b$date + .h) |&gt;\n  summarize(value = sum(discharge == \"No\"), .by = date)\n\n# Add in time 0 row\nfig_2b$current_admit_data &lt;- bind_rows(\n  count(fig_2b$base_data, date, name = \"value\"),\n  fig_2b$current_admit_data\n)\n\nfig_2b$new_admit_data &lt;- admission_data |&gt;\n  filter(date == fig_2b$date) |&gt;\n  unnest(census_contribution) |&gt;\n  filter(h &lt;= fig_2b$h) |&gt;\n  mutate(date = date + h) |&gt;\n  summarize(value = sum(actual), .by = date)\n\n# Add in time 0 row\nfig_2b$new_admit_data &lt;- bind_rows(\n  tibble(date = fig_2b$date, value = 0),\n  fig_2b$new_admit_data\n)\n\nfig_2b$data &lt;- inner_join(\n  rename(fig_2b$current_admit_data, current = value),\n  rename(fig_2b$new_admit_data, new = value),\n  by = \"date\",\n  relationship = \"one-to-one\",\n  unmatched = \"error\"\n) |&gt;\n  mutate(total = current + new, x = row_number() - 1) |&gt;\n  select(-date)\n\nfig_2b$text_y &lt;- 6\n\ncomponents &lt;- list()\ncomponents$names &lt;- c(\"current\", \"new\", \"total\")\ncomponents$labs &lt;- c(\"Current Admissions Component\", \"Future Admissions Component\", \"Total\")\ncomponents$colors &lt;- chop_colors(c(\"pink\", \"blue\", \"green\"))\n\nlevels &lt;- components$names |&gt;\n  set_names(components$labs)\n\ncolors &lt;- components$colors |&gt;\n  set_names(components$labs)\n\nfig_2b$data |&gt;\n  pivot_longer(-x) |&gt;\n  mutate(name = fct_recode(\n    factor(name, components$names),\n    !!!levels\n  )) |&gt;\n  ggplot(aes(x = x, y = value, color = name)) +\n  geom_line(aes(linewidth = name)) +\n  geom_vline(xintercept = c(0, 30)) +\n  annotate(\"text\",\n    y = fig_2b$text_y,\n    x = 30,\n    label = \"Prediction Horizon\",\n    angle = 90,\n    vjust = -.25\n  ) +\n  annotate(\"text\",\n    y = fig_2b$text_y,\n    x = 0,\n    label = \"Current Time\",\n    angle = 90,\n    vjust = -.25\n  ) +\n  labs(\n    color = NULL,\n    y = \"Midnight Census\",\n    x = NULL\n  ) +\n  coord_cartesian(xlim = c(as_date(NA), fig_2b$h - 5)) +\n  scale_linewidth_manual(values = c(Total = 1), na.value = .5, guide = \"none\") +\n  scale_color_manual(values = colors) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\n\n\n\nGenerate descriptive statistics of LOS and admission rates (Table 1)\n\n\ntable_1 &lt;- list()\n\ntable_1$los_data &lt;- manuscript_encounter_data |&gt;\n  summarize(\n    median = median(los),\n    q1 = quantile(los, probs = .25),\n    q3 = quantile(los, probs = .75),\n    .by = admission_type_malig\n  )\n\ntable_1$census_share_data &lt;- manuscript_census_data |&gt;\n  filter(time &gt; 0, date &gt;= \"2016-01-01\") |&gt;\n  count(date, admission_type_malig, name = \"value\") |&gt;\n  complete(\n    date = seq(as_date(\"2016-01-01\"), as_date(\"2023-06-30\"), by = \"day\"),\n    admission_type_malig,\n    fill = list(value = 0)\n  ) |&gt;\n  mutate(pct = value / sum(value), .by = date) |&gt;\n  summarize(pct = mean(pct), .by = admission_type_malig)\n\ntable_1$census_share_data |&gt;\n  arrange(admission_type_malig) |&gt;\n  left_join(table_1$los_data, by = \"admission_type_malig\") |&gt;\n  mutate(\n    across(c(median, q1, q3), \\(x) round(x, 1)),\n    q1_q3 = paste(q1, q3, sep = \", \"),\n    pct = paste0(round(pct*100, 1), \"%\")\n  ) |&gt;\n  select(\n    `Admission Type` = admission_type_malig,\n    `Average % of Census` = pct,\n    `Median LOS (Days)` = median,\n    `LOS Q1, Q3 (Days)` = q1_q3\n  )\n\n\n\n\n\n\n\n\n\n\n\nAdmission Type\nAverage % of Census\nMedian LOS (Days)\nLOS Q1, Q3 (Days)\n\n\n\n\nAuto HSCT\n21.4%\n26.7\n22.7, 34\n\n\nAllo HSCT (Malignant)\n25.3%\n40.9\n35.1, 54\n\n\nAllo HSCT (Non-Malignant)\n29%\n37.1\n31.3, 52.1\n\n\nOther\n24.3%\n3.0\n1.5, 7.6"
  },
  {
    "objectID": "manuscript/reproducibility.html#model-selection",
    "href": "manuscript/reproducibility.html#model-selection",
    "title": "Reproducibility Supplement",
    "section": "Model Selection",
    "text": "Model Selection\n\n\nSplit census data into train and test set\n\nPatients may have multiple encounters. In order to prevent leakage between training and testing we remove patients from the training data that appear in the test set.\n\ncensus_data_split &lt;- census_data |&gt;\n  # Don't need these extra columns\n  select(!any_of(c(\"admission_type\", \"admit_sched_date\"))) |&gt;\n  train_test_split(split_date = train_test_split_date)\n\n\n\n\nSplit admission data into train and test set\n\n\ntest_length &lt;- as.numeric(max(admission_data$date) - train_test_split_date, unit = \"days\")\n\nadmissions_ts_split &lt;- admission_data |&gt;\n  time_series_split(\n    date_var = date,\n    assess = test_length,\n    cumulative = TRUE\n  )\n\n\ndischarge_train &lt;- training(census_data_split)\nadmission_train &lt;- training(admissions_ts_split)\n\ndischarge_test &lt;- testing(census_data_split)\nadmission_test &lt;- testing(admissions_ts_split)\n\nsave_data(census_data_split, \"manuscript/data-split/census.rds\")\nsave_data(admissions_ts_split, \"manuscript/data-split/admissions.rds\")\n\n\n\n\nDefine candidates for discharge and admission models\n\nThe discharge model is a binary classification model predicting discharge on a given day.\nThe admission model is a count model predicting the number of new admissions per day by transplant_type.\nDischarge: - Logistic Regression - XGBoost\nAdmission: - Poisson Regression - XGBoost\n\ndischarge_models &lt;- list(\n  logistic = logistic_reg(),\n  xgboost = boost_tree(mode = \"classification\")\n)\n\ndischarge_wflowset &lt;- workflow_set(\n  preproc = list(baseline = discharge_rec(discharge_train)),\n  models = discharge_models\n)\n\nadmission_wflow_poisson &lt;- workflow(\n  preprocessor = admission_rec(admission_train, type = \"poisson\"),\n  spec = poisson_reg(\"regression\")\n)\n\nadmission_wflow_xgb &lt;- workflow(\n  preprocessor = admission_rec(admission_train, type = \"xgb\"),\n  spec = boost_tree(\"regression\") |&gt;\n    set_engine(\"xgboost\", objective = \"count:poisson\")\n)\n\nadmission_model_tbl &lt;- modeltime_table(\n  fit(admission_wflow_poisson, admission_train),\n  fit(admission_wflow_xgb, admission_train)\n)\n\nadmission_model_tbl$.model_id &lt;- c(\"poisson\", \"xgboost\")\n\n\n\n\nCreate folds for cross-validation\n\nA single fold consists of a discharge fold and an admission fold aligned by prediction date, the first date in the test split of the fold.\nEach discharge fold contains:\n\nA test split with the census on the prediction date\nA train split with the census for all days before the prediction date\n\nEach admission fold contains:\n\nA test split with admissions data for the prediction date and the 90 days after\nA train split admission data for all days before the prediction date\n\n\nsplits &lt;- make_cv_splits(\n  discharge_train,\n  admission_train,\n  h = 90,\n  scheduled_admissions = scheduled_admissions\n)\n\n\n\n\nRun cross-validation to compare candidate models\n\n\ndischarge_results_cv &lt;- fit_discharge_resamples(discharge_wflowset, splits)\n\nadmission_results_cv &lt;- fit_admission_resamples(admission_model_tbl, splits$admission)\n\ncv_results &lt;- collect_cv_results(admission_results_cv, discharge_results_cv, splits)\n\nsave_data(cv_results, \"manuscript/results/cv_results.rds\")\n\n\n\n\nCompute RMSE for model selection results\n\n\ncv_results_summary &lt;- cv_results |&gt;\n  select(admission_model, discharge_model, id, results) |&gt;\n  unnest(results) |&gt;\n  filter(.h %in% c(15, 30, 60, 90)) |&gt;\n  pivot_longer(\n    matches(\"actual|pred\"),\n    names_to = c(\".value\", \"stat\"),\n    names_pattern = \"\\\\.(actual|pred)_(.+)\"\n  ) |&gt;\n  group_by(admission_model, discharge_model, stat, .h) |&gt;\n  rmse(actual, pred) |&gt;\n  filter(stat == \"census\")\n\n\n\n\nGenerate line plot of model RMSE over prediction horizon\n\n\ncv_results_summary |&gt;\n  ggplot(aes(color = paste(admission_model, discharge_model, sep = \"; \"), y = .estimate, x = factor(.h))) +\n  geom_point() +\n  geom_line(aes(group = paste(admission_model, discharge_model))) +\n  labs(y = \"RMSE\", x = \"h (days ahead)\", color = NULL)"
  },
  {
    "objectID": "manuscript/reproducibility.html#model-tuning",
    "href": "manuscript/reproducibility.html#model-tuning",
    "title": "Reproducibility Supplement",
    "section": "Model Tuning",
    "text": "Model Tuning\nHaving selected the XGBoost model for both the admission and discharge models we now jointly tune all hyperparameters using grid search.\n\n\nCreate tuning grid for discharge model\n\n\ndischarge_model_tune &lt;- boost_tree(\n  mode = \"classification\",\n  sample_size = tune(),\n  learn_rate = tune(),\n  trees = 1000,\n  min_n = tune(),\n  mtry = tune()\n)\n\nparams &lt;- discharge_model_tune |&gt;\n  extract_parameter_set_dials() |&gt;\n  finalize(bake(prep(discharge_rec(discharge_train)), new_data = NULL))\n\ndischarge_wflowset_tune &lt;- workflow_set(\n  preproc = list(baseline = discharge_rec(discharge_train)),\n  models = list(xgboost = discharge_model_tune)\n) |&gt;\n  option_add(grid = 20, param_info = params)\n\n\n\n\nFit models on discharge tuning grid\n\n\nplan(\"multisession\")\n\ndischarge_results_tune &lt;- fit_discharge_resamples(discharge_wflowset_tune, splits)\n\nplan(\"sequential\")\n\n\n\n\nCreate tuning grid for admission model\n\n\nadmission_model_tune &lt;- boost_tree(\n  mode = \"regression\",\n  trees = 1000,\n  sample_size = tune(),\n  learn_rate = tune(),\n  min_n = tune(),\n  mtry = tune()\n) |&gt;\n  set_engine(\"xgboost\", objective = \"count:poisson\")\n\nadmission_grid &lt;- admission_model_tune |&gt;\n  extract_parameter_set_dials() |&gt;\n  finalize(juice(prep(admission_rec(admission_train, type = \"xgb\")))) |&gt;\n  grid_space_filling(size = 20)\n\nadmission_model_grid &lt;- create_model_grid(\n  grid = admission_grid,\n  f_model_spec = boost_tree,\n  engine_name = \"xgboost\",\n  mode = \"regression\",\n  trees = 1000,\n  engine_params = list(objective = \"count:poisson\")\n)\n\n\n\n\nFit models on admission tuning grid\n\n\nplan(\"multisession\")\n\nadmission_model_tbl_tune &lt;- workflow_set(\n  preproc = list(admission_rec(admission_train, type = \"xgb\")),\n  models = admission_model_grid$.models\n) |&gt;\n  modeltime_fit_workflowset(data = admission_train, control = control_fit_workflowset(allow_par = TRUE))\n\nadmission_model_tbl_tune$.model_id &lt;- \"xgboost\"\nadmission_model_tbl_tune$.config &lt;- 1:nrow(admission_model_tbl_tune)\nadmission_model_tbl_tune$hyperparams &lt;- admission_model_grid |&gt;\n  select(-.models) |&gt;\n  pmap(tibble)\n\nadmission_results_tune &lt;- fit_admission_resamples(admission_model_tbl_tune, splits$admission)\n\nplan(\"sequential\")\n\n\n\n\nGenerate results for joint discharge-admission tuning grid\n\n\nplan(\"multisession\")\n\ntune_results &lt;- collect_cv_results(admission_results_tune, discharge_results_tune, splits)\n\nplan(\"sequential\")\n\nsave_data(tune_results, \"manuscript/results/tune_results.rds\")\n\n\n\n\nPlot ranked MAPE for top 30 model configuration\n\n\nmset &lt;- metric_set(rmse, mape)\n\ntune_results_summary &lt;- tune_results |&gt;\n  rename(discharge = discharge_hyperparams, admission = admission_hyperparams) |&gt;\n  unnest(c(discharge, admission), names_sep = \"_\") |&gt;\n  unnest(results) |&gt;\n  filter(.h %in% c(15, 30, 60, 90)) |&gt;\n  pivot_longer(\n    matches(\"actual|pred\"),\n    names_to = c(\".value\", \"stat\"),\n    names_pattern = \"\\\\.(actual|pred)_(.+)\"\n  ) |&gt;\n  group_by(admission_config, discharge_config, stat, .h, pick(matches(\"mtry|min_n|learn_rate|sample_size$\"))) |&gt;\n  mset(actual, pred) |&gt;\n  filter(stat == \"census\")\n\n\ntune_results_summary |&gt;\n  filter(.metric == \"mape\") |&gt;\n  mutate(avg_estimate = mean(.estimate), .by = c(admission_config, discharge_config)) |&gt;\n  mutate(rank = rank(.estimate), .by = .h) |&gt;\n  mutate(avg_rank = dense_rank(avg_estimate)) |&gt;\n  filter(avg_rank &lt;= 30) |&gt;\n  ggplot(aes(y = fct_rev(factor(avg_rank)), x = rank)) +\n  geom_jitter(aes(color = factor(.h)), height = 0)\n\n\n\n\n\n\n\n\n\n\n\nPlot ranked RMSE for top 30 model configuration\n\n\ntune_results_summary |&gt;\n  filter(.metric == \"rmse\") |&gt;\n  mutate(avg_estimate = mean(.estimate), .by = c(admission_config, discharge_config)) |&gt;\n  mutate(rank = rank(.estimate), .by = .h) |&gt;\n  mutate(avg_rank = dense_rank(avg_estimate)) |&gt;\n  filter(avg_rank &lt;= 30) |&gt;\n  ggplot(aes(y = fct_rev(factor(avg_rank)), x = rank)) +\n  geom_jitter(aes(color = factor(.h)), height = 0)\n\n\n\n\n\n\n\n\n\n\n\nSelect model with minimal RMSE\n\n\nbest_config &lt;- tune_results_summary |&gt;\n  filter(.metric == \"rmse\") |&gt;\n  mutate(avg_estimate = mean(.estimate), .by = c(admission_config, discharge_config)) |&gt;\n  filter(dense_rank(avg_estimate) == 1) |&gt;\n  distinct(admission_config, discharge_config)\n\nfinal_params &lt;- tune_results |&gt;\n  filter(\n    discharge_config == best_config$discharge_config,\n    admission_config == best_config$admission_config\n  ) |&gt;\n  distinct(admission_hyperparams, discharge_hyperparams) |&gt;\n  as.list() |&gt;\n  map(pluck(1))\n\nfinal_params$admission_hyperparams\n\n\n\n\n\nmtry\nmin_n\nlearn_rate\nsample_size\n\n\n\n\n3\n9\n0.0036468\n0.9712415\n\n\n\n\n\nfinal_params$discharge_hyperparams\n\n\n\n\n\nmtry\nmin_n\nlearn_rate\nsample_size\n\n\n\n\n6\n28\n0.005141\n0.1383986"
  },
  {
    "objectID": "manuscript/reproducibility.html#model-evaluation",
    "href": "manuscript/reproducibility.html#model-evaluation",
    "title": "Reproducibility Supplement",
    "section": "Model Evaluation",
    "text": "Model Evaluation\n\n\nFit selected model on full training data\n\n\ndischarge_model_train &lt;- workflow(\n  discharge_rec(discharge_train),\n  discharge_model_tune\n) |&gt;\n  finalize_workflow(final_params$discharge_hyperparams) |&gt;\n  fit(discharge_train)\n\nadmission_model_train &lt;- workflow(\n  admission_rec(admission_train, type = \"xgb\"),\n  admission_model_tune\n) |&gt;\n  finalize_workflow(final_params$admission_hyperparams) |&gt;\n  fit(admission_train) |&gt;\n  modeltime_table()\n\nmodels_train &lt;- bmt_model(discharge_model = discharge_model_train, admission_model = admission_model_train)\n\nsave_data(models_train, \"manuscript/models/models_train.rds\")\n\n\n\n\nPredict on held-out test data\n\n\ntest_dates &lt;- unique(admission_test$date)\n\ntest_results &lt;- make_test_data(test_dates, discharge_test, admission_test, scheduled_admissions)\n\ntest_results$results &lt;- pmap(test_results, \\(current_admissions, scheduled_admissions, ...) {\n  predict_census(\n    models = models_train,\n    h = 1:90,\n    current_census = current_admissions,\n    scheduled_admissions = scheduled_admissions\n  )\n})\n\nsave_data(test_results, \"manuscript/results/test_results.rds\")\n\n\n\nProspective validation data are the results of an automated process that made daily, prospective predictions of the census.\n\nLoad prospective validation data\n\n\nvalidation_results &lt;- readRDS(\"manuscript/data/validation_results.rds\")\n\nwithr::with_seed(71919, {\n  validation_results_bootstrap &lt;- validation_results |&gt;\n    filter(.h %in% c(15, 30, 60), !is.na(.actual_census)) |&gt;\n    generate_bootstraps(bootstrap_block_size = 7)\n})\n\n\n\n\nCalculate evaluation metrics for test set and prospective validation (Table 2)\n\n\nmanuscript_test_results &lt;- left_join(\n  test_results |&gt;\n    select(test_date, results) |&gt;\n    unnest(results),\n  test_results |&gt;\n    select(test_date, actual) |&gt;\n    unnest(actual),\n  by = c(\"test_date\", \".h\")\n  ) |&gt;\n  filter(.h &lt;= 60)\n\ntable_2 &lt;- list()\n\ntable_2$test &lt;- make_metrics_table(manuscript_test_results) |&gt;\n  filter(Component == \"Total Census\") |&gt;\n  select(-Component)\n\ntable_2$validation &lt;- make_metrics_table(validation_results) |&gt;\n  filter(Component == \"Total Census\") |&gt;\n  select(-Component)\n\ntable_2$thresholds &lt;- tibble(\n  Horizon = c(15, 30, 60),\n  `Prospective Validation MAPE Threshold` = c(15, 20, 25),\n  `Prospective Validation Result` = \"Pass\"\n)\n\ntable_2$boot &lt;- summarize_bootstrap(validation_results_bootstrap)$table |&gt;\n  filter(.metric == \"mape\") |&gt;\n  select(Horizon = .h, `Prospective Validation MAPE 95% Bound` = `0.95`)\n\nleft_join(\n  rename_with(table_2$test, \\(x) paste(\"Test Set\", x), c(RMSE, MAPE)),\n  rename_with(table_2$validation, \\(x) paste(\"Prospective Validation\", x), c(RMSE, MAPE)),\n  by = \"Horizon\"\n) |&gt;\n  left_join(table_2$boot, by = \"Horizon\") |&gt;\n  left_join(table_2$thresholds, by = \"Horizon\") |&gt;\n  mutate(\n    across(ends_with(\"RMSE\"), \\(x) round(x, 1)),\n    across(ends_with(\"MAPE\"), \\(x) round(x, 1)),\n    across(ends_with(\"MAPE 95% Bound\"), \\(x) round(x, 1))\n  ) |&gt;\n  kbl(\n    col.names = c(\n      \"Prediction Horizon (Days)\",\n      \"RMSE\",\n      \"MAPE\",\n      \"RMSE\",\n      \"MAPE\",\n      \"MAPE 95% Upper Bound\",\n      \"MAPE 95% Upper Bound Threshold\",\n      \"Result\"\n    ),\n    align = \"c\"\n  ) |&gt;\n  add_header_above(c(\" \" = 1, \"Held-out Test Set\" = 2, \"Prospective Validation\" = 5), bold = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHeld-out Test Set\n\n\nProspective Validation\n\n\n\nPrediction Horizon (Days)\nRMSE\nMAPE\nRMSE\nMAPE\nMAPE 95% Upper Bound\nMAPE 95% Upper Bound Threshold\nResult\n\n\n\n\n15\n2.5\n13.2\n2.5\n12.4\n12.3\n15\nPass\n\n\n30\n3.1\n16.4\n1.7\n8.1\n7.8\n20\nPass\n\n\n60\n3.6\n18.2\n2.5\n11.2\n12.2\n25\nPass\n\n\n\n\n\n\n\n\nPlot total census predictions for the test set (Figure 3a)\n\n\nmanuscript_test_results |&gt;\n  plot_results(.pred_census, .actual_census)\n\n\n\n\n\n\n\n\n\n\n\nPlot total census predictions for the prospective validation (Figure 3b)\n\n\nvalidation_results |&gt;\n  plot_results(.pred_census, .actual_census) +\n  scale_y_continuous(breaks = c(12, 15, 18, 21))\n\n\n\n\n\n\n\n\n\n\n\nPlot sample prediction curves for current admissions component on the test set (Figure S1a)\n\n\nmanuscript_test_results |&gt;\n  plot_prediction_curves(\n    pred = .pred_current_admission,\n    actual = .actual_current_admission,\n    group = test_date,\n    n_show = 10\n  )\n\n\n\n\n\n\n\n\n\n\n\nPlot sample prediction curves for current admissions component on the prospective validation (Figure S1b)\n\n\nvalidation_results |&gt;\n  filter(max(.h) == 60, .by = prediction_date) |&gt;\n  plot_prediction_curves(\n    pred = .pred_current_admission,\n    actual = .actual_current_admission,\n    group = prediction_date,\n    n_show = 6\n  )\n\n\n\n\n\n\n\n\n\n\n\nPlot sample prediction curves for future admissions component on the test set (Figure S2a)\n\n\nmanuscript_test_results |&gt;\n  plot_prediction_curves(\n    pred = .pred_new_admission,\n    actual = .actual_new_admission,\n    group = test_date,\n    n_show = 10\n  )\n\n\n\n\n\n\n\n\n\n\n\nPlot sample prediction curves for future admissions component on the prospective validation (Figure S2b)\n\n\nvalidation_results |&gt;\n  filter(max(.h) == 60, .by = prediction_date) |&gt;\n  plot_prediction_curves(\n    pred = .pred_new_admission,\n    actual = .actual_new_admission,\n    group = prediction_date,\n    n_show = 6\n  )\n\n\n\n\n\n\n\n\n\n\n\nFit model on full dataset\n\n\ndischarge_model_final &lt;- fit(models_train$discharge, census_data)\n\nadmission_model_final &lt;- modeltime_refit(models_train$admission, admission_data)\n\nmodels_final &lt;- bmt_model(discharge_model = discharge_model_final, admission_model = admission_model_final)\n\nsave_data(models_final, \"manuscript/models/models_final.rds\")"
  },
  {
    "objectID": "manuscript/reproducibility.html#supplementary-analyses",
    "href": "manuscript/reproducibility.html#supplementary-analyses",
    "title": "Reproducibility Supplement",
    "section": "Supplementary Analyses",
    "text": "Supplementary Analyses\n\n\nCreate total census time series\n\n\ncensus_ts_data &lt;- census_data |&gt;\n  filter(time &gt; 0, date &gt;= \"2016-01-01\") |&gt;\n  count(date, name = \"value\")\n\ncensus_ts_split &lt;- census_ts_data |&gt;\n  time_series_split(\n    date_var = date,\n    assess = test_length,\n    cumulative = TRUE\n  )\n\ncensus_ts_train &lt;- training(census_ts_split)\n\nreframe(census_ts_train, range(date))\n\n\n\n\n\nrange(date)\n\n\n\n\n2016-01-01\n\n\n2022-09-30\n\n\n\n\n\ncensus_ts_test &lt;- testing(census_ts_split)\n\nreframe(census_ts_test, range(date))\n\n\n\n\n\nrange(date)\n\n\n\n\n2022-10-01\n\n\n2023-06-30\n\n\n\n\n\n\n\n\n\nPredict test set using heuristic models\n\n\npost_process_naive_results &lt;- function(results, h) {\n  out &lt;- select(results, .model_desc)\n  \n  out$preds &lt;- results$.resample_results |&gt;\n    map(\\(x) {\n      x |&gt;\n        select(id, .predictions) |&gt;\n        unnest(.predictions) |&gt;\n        mutate(.h = row_number(), .by = id) |&gt;\n        slice(h, .by = id)\n    })\n  \n  out |&gt; unnest(preds)\n}\n\n# Include prior year of data for seasonal naive model \ncensus_ts_test_leadin &lt;- bind_rows(\n  census_ts_train |&gt;\n    filter(date &gt; train_test_split_date - 365),\n  census_ts_test\n)\n\nnaive_models &lt;- modeltime_table(\n  naive_reg() |&gt;\n    set_engine(\"naive\") |&gt;\n    fit(value ~ date, census_ts_train),\n  naive_reg(seasonal_period = 12) |&gt;\n    set_engine(\"snaive\") |&gt;\n    fit(value ~ date, census_ts_train)\n)\n\ncensus_ts_test_leadin_split &lt;- time_series_cv(\n  census_ts_test_leadin,\n  date_var = date,\n  assess = \"60 days\",\n  initial = 365,\n  cumulative = TRUE\n)\n\nnaive_results &lt;- naive_models |&gt;\n  modeltime_fit_resamples(census_ts_test_leadin_split) |&gt;\n  post_process_naive_results(h = c(15, 30, 60))\n\nmean_results &lt;- tibble(\n  id = census_ts_test_leadin_split$id,\n  .pred = map_dbl(census_ts_test_leadin_split$splits, \\(x) mean(training(x)$value))\n)\n\nheuristic_results &lt;- bind_rows(\n  naive_results,\n  naive_results |&gt;\n    select(-.pred) |&gt;\n    mutate(.model_desc = \"MEAN\") |&gt;\n    left_join(mean_results, by = \"id\", relationship = \"many-to-one\", unmatched = \"error\")\n)\n\nsave_data(heuristic_results, \"manuscript/results/heuristic_results.rds\")\n\n\n\n\nFit simple time series models\n\n\nts_wflow_poisson &lt;- workflow(\n  preprocessor = admission_rec(census_ts_train, type = \"poisson\"),\n  spec = poisson_reg(\"regression\")\n)\n\nts_wflow_xgb &lt;- workflow(\n  preprocessor = admission_rec(census_ts_train, type = \"xgb\"),\n  spec = boost_tree(\n    \"regression\",\n    trees = 1000\n  ) |&gt;\n    set_engine(\"xgboost\", objective = \"count:poisson\")\n)\n\nts_models &lt;- modeltime_table(\n  fit(ts_wflow_poisson, census_ts_train),\n  fit(ts_wflow_xgb, census_ts_train)\n) |&gt;\n  update_modeltime_description(1, \"poisson\") |&gt;\n  update_modeltime_description(2, \"xgboost\")\n\n\n\n\nCreate tuning grid for simple time series models\n\n\nts_xgb_tune_split &lt;- make_census_ts_splits(census_ts_train, 60, slice_limit = 15, skip = \"3 months\")\n\nts_xgb_tune &lt;- boost_tree(\n  mode = \"regression\",\n  trees = 1000,\n  sample_size = tune(),\n  learn_rate = tune(),\n  min_n = tune(),\n  mtry = tune()\n) |&gt;\n  set_engine(\"xgboost\", objective = \"count:poisson\")\n\nts_xgb_grid &lt;- ts_xgb_tune |&gt;\n  extract_parameter_set_dials() |&gt;\n  update(learn_rate = learn_rate(range = c(-2.3, -1.6))) |&gt;\n  finalize(juice(prep(admission_rec(census_ts_train, type = \"xgb\")))) |&gt;\n  grid_space_filling(size = 20)\n\nts_xgb_model_grid &lt;- create_model_grid(\n  grid = ts_xgb_grid,\n  f_model_spec = boost_tree,\n  engine_name = \"xgboost\",\n  mode = \"regression\",\n  trees = 1000,\n  engine_params = list(objective = \"count:poisson\")\n)\n\n\n\n\nFit models on time series tuning grid\n\n\nplan(\"multisession\")\n\nts_xgb_model_tbl_tune &lt;- workflow_set(\n  preproc = list(admission_rec(census_ts_train, type = \"xgb\")),\n  models = ts_xgb_model_grid$.models\n) |&gt;\n  modeltime_fit_workflowset(data = census_ts_train, control = control_fit_workflowset(allow_par = TRUE))\n\nts_xgb_model_tbl_tune$.config &lt;- 1:nrow(ts_xgb_model_tbl_tune)\nts_xgb_model_tbl_tune$hyperparams &lt;- ts_xgb_model_grid |&gt;\n  select(-.models) |&gt;\n  pmap(tibble)\n\nts_tune_results &lt;- modeltime_fit_resamples(\n  ts_xgb_model_tbl_tune,\n  resamples = ts_xgb_tune_split\n) |&gt;\n  postprocess_ts_resamples(pred_name = \".pred\")\n\nplan(\"sequential\")\n\nsave_data(ts_tune_results, \"manuscript/results/ts_tune_results.rds\")\n\n\n\n\nPlot RMSE and MAPE for all configurations in tuning grid\n\n\nts_tune_results_summary &lt;- ts_tune_results |&gt;\n  unnest(hyperparams) |&gt;\n  unnest(results) |&gt;\n  filter(.h %in% c(15, 30, 60)) |&gt;\n  group_by(.model_id, .h, .config, pick(matches(\"mtry|min_n|learn_rate|sample_size$\"))) |&gt;\n  mset(value, .pred)\n\nts_tune_results_summary |&gt;\n  ggplot(aes(x = .estimate, y = factor(.config), color = factor(.h))) +\n  geom_point() +\n  facet_wrap(~.metric, scales = \"free_x\")\n\n\n\n\n\n\n\n\n\n\n\nSelect time series model with minimal RMSE\n\n\nts_best_config &lt;- ts_tune_results_summary |&gt;\n  filter(.metric == \"rmse\") |&gt;\n  mutate(avg_estimate = mean(.estimate), .by = .config) |&gt;\n  filter(dense_rank(avg_estimate) == 1) |&gt;\n  distinct(.config)\n\nts_final_params &lt;- ts_tune_results |&gt;\n  filter(\n    .config == ts_best_config$.config\n  ) |&gt;\n  distinct(hyperparams) |&gt;\n  pull(hyperparams) |&gt;\n  pluck(1)\n\nts_final_params\n\n\n\n\n\nmtry\nmin_n\nlearn_rate\nsample_size\n\n\n\n\n1\n14\n0.0164357\n0.4315789\n\n\n\n\n\nts_xgb_tuned &lt;- workflow(\n  admission_rec(census_ts_train, type = \"xgb\"),\n  ts_xgb_tune\n) |&gt;\n  finalize_workflow(ts_final_params) |&gt;\n  fit(census_ts_train) |&gt;\n  modeltime_table()\n\n\n\n\nPredict on test set with all time series models\n\n\n# Add tuned xgb to models\nts_models &lt;- combine_modeltime_tables(\n  ts_models,\n  ts_xgb_tuned\n) |&gt;\n  update_modeltime_description(3, \"xgboost tuned\")\n\nforecast_test_date &lt;- function(test_date, test_data, models, h = 1:60) {\n  max_h &lt;- max(h)\n  new_data &lt;- tibble(\n    date = seq(test_date, test_date + max_h - 1, by = \"day\"),\n    .h = 1:max_h\n  ) |&gt;\n    left_join(test_data, by = \"date\")\n  \n  models |&gt;\n    modeltime_calibrate(new_data = new_data) |&gt;\n    modeltime_forecast(\n      new_data,\n      keep_data = TRUE\n    ) |&gt;\n      filter(.h %in% h) |&gt;\n      select(all_of(colnames(new_data)), .value, .model_id, .model_desc)\n}\n\n# Sample 40 test dates for prediction\nts_test_dates &lt;- census_ts_test |&gt;\n  filter(!is.na(lead(value, 60))) |&gt;\n  pull(date) |&gt;\n  unique() |&gt;\n  sample(40)\n\nts_test_results &lt;- tibble(test_date = ts_test_dates)\n\nts_test_results$results &lt;- map(\n  ts_test_results$test_date,\n  forecast_test_date,\n  test_data = census_ts_test,\n  models = ts_models\n)\n\nsaveRDS(ts_test_results, \"manuscript/results/ts_test_results.rds\")\n\n\n\n\nCreate summary metrics table for heuristic and time series models (Table S1)\n\n\nheuristic_results_summary &lt;- heuristic_results |&gt;\n  group_by(.model_desc, .h) |&gt;\n  mset(value, .pred)\n\nts_results_summary &lt;- ts_test_results |&gt;\n  unnest(results) |&gt;\n  filter(.h %in% c(15, 30, 60), !is.na(value)) |&gt;\n  group_by(.model_desc, .h) |&gt;\n  mset(value, .value)\n\nbind_rows(\n  heuristic_results_summary,\n  ts_results_summary |&gt;\n    filter(.model_desc %in% c(\"poisson\", \"xgboost tuned\")),\n  table_2$test |&gt;\n    select(.h = Horizon, mape = MAPE, rmse = RMSE) |&gt;\n    pivot_longer(c(mape, rmse), names_to = \".metric\", values_to = \".estimate\") |&gt;\n    mutate(.model_desc = \"Preferred\")\n) |&gt;\n  mutate(\n    .model_desc = case_match(\n      .model_desc,\n      \"MEAN\" ~ \"Mean\",\n      \"SNAIVE [12]\" ~ \"Seasonal Naive\",\n      \"NAIVE\" ~ \"Naive\",\n      \"poisson\" ~ \"Poisson\",\n      \"xgboost tuned\" ~ \"GBDT\",\n      .default = .model_desc\n    ),\n    model_type = case_match(\n      .model_desc,\n      c(\"Mean\", \"Seasonal Naive\", \"Naive\") ~ \"Heuristic Model\",\n      c(\"Poisson\", \"GBDT\") ~ \"Time Series Model\",\n      \"Preferred\" ~ \"Component-based Model\"\n    ),\n    .estimate = round(.estimate, 1)\n  ) |&gt;\n  pivot_wider(id_cols = c(.h, model_type, .model_desc), names_from = .metric, values_from = .estimate) |&gt;\n  kbl(\n    col.names = c(\n    \"Prediction Horizon (Days)\",\n    \"Model Type\",\n    \"Model\",\n    \"RMSE\",\n    \"MAPE\"\n  ),\n    align = \"c\"\n  ) |&gt;\n  row_spec(16:18, bold = TRUE)\n\n\n\n\nPrediction Horizon (Days)\nModel Type\nModel\nRMSE\nMAPE\n\n\n\n\n15\nHeuristic Model\nMean\n4.4\n30.9\n\n\n30\nHeuristic Model\nMean\n4.5\n31.6\n\n\n60\nHeuristic Model\nMean\n4.6\n31.9\n\n\n15\nHeuristic Model\nNaive\n3.6\n19.7\n\n\n30\nHeuristic Model\nNaive\n4.3\n24.6\n\n\n60\nHeuristic Model\nNaive\n5.6\n30.6\n\n\n15\nHeuristic Model\nSeasonal Naive\n4.0\n21.9\n\n\n30\nHeuristic Model\nSeasonal Naive\n4.6\n27.1\n\n\n60\nHeuristic Model\nSeasonal Naive\n5.6\n30.6\n\n\n15\nTime Series Model\nPoisson\n3.1\n20.9\n\n\n30\nTime Series Model\nPoisson\n3.1\n20.4\n\n\n60\nTime Series Model\nPoisson\n3.7\n23.1\n\n\n15\nTime Series Model\nGBDT\n3.2\n21.6\n\n\n30\nTime Series Model\nGBDT\n3.1\n20.6\n\n\n60\nTime Series Model\nGBDT\n3.9\n23.2\n\n\n15\nComponent-based Model\nPreferred\n2.5\n13.2\n\n\n30\nComponent-based Model\nPreferred\n3.1\n16.4\n\n\n60\nComponent-based Model\nPreferred\n3.6\n18.2"
  }
]